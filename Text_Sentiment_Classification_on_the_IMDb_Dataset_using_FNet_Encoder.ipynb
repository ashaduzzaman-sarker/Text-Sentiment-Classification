{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashaduzzaman-sarker/Text-classification-Sentiment-Analysis/blob/main/Text_Sentiment_Classification_on_the_IMDb_Dataset_using_FNet_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEDtybEMbSQN"
      },
      "source": [
        "# Text Classification on the IMDb Dataset using FNet Encoder\n",
        "\n",
        "## [FNet: Mixing Tokens with Fourier Transforms](https://doi.org/10.48550/arXiv.2105.03824)\n",
        "\n",
        "The FNet encoder model, introduced by Google Research, is a type of transformer model that replaces the self-attention mechanism with a Fourier Transform. This approach significantly reduces the computational complexity while maintaining competitive performance in various natural language processing tasks. Here's a detailed explanation:\n",
        "\n",
        "### Key Concepts and Components\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1010/1*7ZfynrPBS6jNIu4U49TMCA.png)\n",
        "\n",
        "1. **Fourier Transform**:\n",
        "   - The core idea of the FNet model is to use the Fourier Transform to capture interactions between different parts of the input sequence. The Fourier Transform helps convert the sequence data from the time domain to the frequency domain, where the global structure of the data can be analyzed more efficiently.\n",
        "   - The Fourier Transform in FNet is applied to the input embeddings or the outputs of the previous layer, effectively replacing the self-attention mechanism used in traditional transformers.\n",
        "\n",
        "2. **Encoder Structure**:\n",
        "   - Similar to the traditional transformer encoder, the FNet encoder consists of multiple layers. Each layer has two main components:\n",
        "     1. **Fourier Transform Layer**: This replaces the self-attention mechanism. The layer applies a 2D Fourier Transform to the input sequence.\n",
        "     2. **Feed-Forward Neural Network (FFN)**: After the Fourier Transform, the output is passed through a position-wise feed-forward neural network, which is the same as in traditional transformers.\n",
        "   - Each layer also includes layer normalization and residual connections to stabilize training and improve performance.\n",
        "\n",
        "3. **Advantages**:\n",
        "   - **Efficiency**: By replacing the self-attention mechanism with a Fourier Transform, the FNet encoder reduces the computational complexity from \\(O(n^2)\\) (where \\(n\\) is the sequence length) to \\(O(n \\log n)\\). This makes it much more efficient, especially for long sequences.\n",
        "   - **Simplicity**: The Fourier Transform is simpler and less resource-intensive than the self-attention mechanism, making the FNet encoder easier to implement and train.\n",
        "\n",
        "4. **Performance**:\n",
        "   - Despite its simplicity and efficiency, the FNet encoder has been shown to perform competitively on various NLP benchmarks, demonstrating that the Fourier Transform can capture important relationships in the data without the need for complex attention mechanisms.\n",
        "\n",
        "### Detailed Workflow\n",
        "\n",
        "1. **Input Embedding**:\n",
        "   - The input tokens are first embedded into a continuous vector space, similar to other transformer models.\n",
        "\n",
        "2. **Fourier Transform Layer**:\n",
        "   - The embedded sequence is transformed using a 2D Fourier Transform. This step captures interactions between all parts of the sequence efficiently.\n",
        "\n",
        "3. **Feed-Forward Layer**:\n",
        "   - The transformed sequence is passed through a feed-forward neural network, which applies a series of linear transformations and non-linear activations.\n",
        "\n",
        "4. **Layer Normalization and Residual Connections**:\n",
        "   - Each layer includes layer normalization and residual connections to maintain stability and enhance gradient flow during training.\n",
        "\n",
        "5. **Output**:\n",
        "   - The output of the last encoder layer is used for downstream tasks, such as classification, sequence labeling, or language modeling.\n",
        "\n",
        "### Applications\n",
        "\n",
        "The FNet encoder can be used in various NLP tasks, including:\n",
        "- Text classification\n",
        "- Named entity recognition\n",
        "- Machine translation\n",
        "- Text generation\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The FNet encoder model is a significant advancement in the field of NLP, offering a more efficient alternative to the traditional transformer architecture by leveraging the Fourier Transform. It maintains competitive performance while reducing computational requirements, making it a promising approach for applications requiring processing of long sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n41BjcxLeB08"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGSY56zkaKJu",
        "outputId": "9b09c5cd-a5f1-4414-8512-d4d840807fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade keras-nlp\n",
        "!pip install -q --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yIxGcUtOePTT"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snEDH8SdeZ_J"
      },
      "source": [
        "## Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uirk48FgeeQ8"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 512\n",
        "VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 128\n",
        "INTERMEDIATE_DIM = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sjRK5e-e1_G"
      },
      "source": [
        "## Loading the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbmKM-mXe3ss",
        "outputId": "e3b7f63a-602e-4296-d52e-2d0f693d85cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-31 03:52:33--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  29.5MB/s    in 2.7s    \n",
            "\n",
            "2024-07-31 03:52:36 (29.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye767TwGfF1G",
        "outputId": "160623cb-280a-4926-c264-ba30464ed478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train', 'README', 'imdb.vocab', 'test', 'imdbEr.txt']\n",
            "['neg', 'urls_neg.txt', 'urls_pos.txt', 'pos', 'labeledBow.feat', 'urls_unsup.txt', 'unsup', 'unsupBow.feat']\n",
            "['neg', 'urls_neg.txt', 'urls_pos.txt', 'pos', 'labeledBow.feat']\n"
          ]
        }
      ],
      "source": [
        "# Let's inspect the structure of the directory\n",
        "print(os.listdir('./aclImdb'))\n",
        "print(os.listdir('./aclImdb/train'))\n",
        "print(os.listdir('./aclImdb/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtWGMK4ehqJS",
        "outputId": "344111b0-9434-480c-e082-2c7577e64ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"The Odd Couple\" is one of those movies that far surpasses its reputation. People all know it, they hum the theme song, they complain of living with a sloppy \"Oscar\" or a fastidious \"Felix\"...but they're under-selling the film without knowing it. This isn't just about a neat guy living with a sloppy guy; it's a portrait of two friends helping each other through the agony of divorce. It's also damn funny from start to finish, but it's the kind of comedy that arises from realistic, stressful, and just plain awful situations. So, some viewers have actually found the film to be a bit uncomfortable, but I think its verisimilitude is its strength. Besides, Matthau's bulldog face just cracks me up! My favorite comedy, by a country mile."
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/pos/11558_10.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIizUL5Qhvzu",
        "outputId": "a1adf25e-6740-455f-eed5-8fd4ba8e8119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I bought this at tower records after seeing the info-mercial about fifteen hundred times on comedy central. I was actually really looking forward to watching this. My god where did i go wrong? Now before i give my review let me just say that i am a person who can pretty much find the good in all movies, hell i own over 1,500 dvd's! With that said, the underground comedy movie ranks up there with the worst film i have EVER seen. I tried to give it a chance, but not only was it not funny. It had no point, did not offend what-so-ever and was all around stupid. God who in their right mind thought these pieces of crap were funny? this is going right to the bottom of the bin..."
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/neg/11008_1.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Co0n4o0KfsKp"
      },
      "outputs": [],
      "source": [
        "# Remove the `unsup` folder as it has unlabelled samples\n",
        "!rm -rf aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiyD1z1chIWu"
      },
      "source": [
        "## Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg3ZFpMigUl0",
        "outputId": "2aaf4457-5bde-4a02-ea28-9c68bfa781f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Number of batches in train_ds: 313\n",
            "Number of batches in val_ds: 79\n",
            "Number of batches in test_ds: 391\n"
          ]
        }
      ],
      "source": [
        "# Generate our labelled tf.data.Dataset dataset from text files\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=42\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f'Number of batches in train_ds: {train_ds.cardinality()}')\n",
        "print(f'Number of batches in val_ds: {val_ds.cardinality()}')\n",
        "print(f'Number of batches in test_ds: {test_ds.cardinality()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnuR_JKZiG28",
        "outputId": "ebcdf68c-e8ee-4214-88a9-ee4d71b0dd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 1: b'An illegal immigrant resists the social support system causing dire consequences for many. Well filmed and acted even though the story is a bit forced, yet the slow pacing really sets off the conclusion. The feeling of being lost in the big city is effectively conveyed. The little person lost in the big society is something to which we can all relate, but I cannot endorse going out of your way to see this movie.'\n",
            "Label 1: 0\n",
            "Review 2: b\"To get in touch with the beauty of this film pay close attention to the sound track, not only the music, but the way all sounds help to weave the imagery. How beautifully the opening scene leading to the expulsion of Gino establishes the theme of moral ambiguity! Note the way music introduces the characters as we are led inside Giovanna's marriage. Don't expect to find much here of the political life of Italy in 1943. That's not what this is about. On the other hand, if you are susceptible to the music of images and sounds, you will be led into a word that reaches beyond neo-realism. By the end of the film we there are moments Antonioni-like landscape that has more to do with the inner life of the characters than with real places. This is one of my favorite Visconti films.\"\n",
            "Label 2: 1\n",
            "Review 3: b'\"Hollywood Hotel\" has relationships to many films like \"Ella Cinders\" and \"Merton of the Movies\" about someone winning a contest including a contract to make films in Hollywood, only to find the road to stardom either paved with pitfalls or non-existent. In fact, as I was watching it tonight, on Turner Classic Movies, I was considering whether or not the authors of the later musical classic \"Singing In The Rain\" may have taken some of their ideas from \"Hollywood Hotel\", most notably a temperamental leading lady star in a movie studio and a conclusion concerning one person singing a film score while another person got the credit by mouthing along on screen.<br /><br />\"Hollywood Hotel\" is a fascinating example of movie making in the 1930s. Among the supporting players is Louella Parsons, playing herself (and, despite some negative comments I\\'ve seen, she has a very ingratiating personality on screen and a natural command of her lines). She is not the only real person in the script. Make-up specialist Perc Westmore briefly appears as himself to try to make one character resemble another.<br /><br />This film also was one of the first in the career of young Mr. Ronald Reagan, playing a radio interviewer at a movie premiere. Reagan actually does quite nicely in his brief scenes - particularly when he realizes that nobody Dick Powell is about to take over the microphone when it should be used with more important people.<br /><br />Dick Powell has won a Hollywood contract in a contest, and is leaving his job as a saxophonist in Benny Goodman\\'s band. The beginning of this film, by the way, is quite impressive, as the band drives in a parade of trucks to give a proper goodbye to Powell. They end up singing \"Hooray For Hollywood\". The interesting thing about this wonderful number is that a lyric has been left out on purpose. Throughout the Johnny Mercer lyrics are references to such Hollywood as Max Factor the make-up king, Rin tin tin, and even a hint of Tarzan. But the original song lyric referred to looking like Tyrone Power. Obviously Jack Warner and his brothers were not going to advertise the leading man of 20th Century Fox, and the name Donald Duck was substituted. In any event the number showed the singers and instrumentalists of Goodman\\'s orchestra at their best. So did a later five minute section of the film, where the band is rehearsing.<br /><br />Powell leaves the band and his girl friend (Frances Langford) and goes to Hollywood, only to find he is a contract player (most likely for musicals involving saxophonists). He is met by Allen Joslyn, the publicist of the studio (the owner is Grant Mitchell). Joslyn is not a bad fellow, but he is busy and he tends to slough off people unless it is necessary to speak to them. He parks Powell at a room at the Hollywood Hotel, which is also where the studio\\'s temperamental star (Lola Lane) lives with her father (Hugh Herbert), her sister (Mabel Todd), and her sensible if cynical assistant (Glenda Farrell). Lane is like Jean Hagen in \"Singing In The Rain\", except her speaking voice is good. Her version of \"Dan Lockwood\" is one \"Alexander Dupre\" (Alan Mowbray, scene stealing with ease several times). The only difference is that Mowbray is not a nice guy like Gene Kelly was, and Lane (when not wrapped up in her ego) is fully aware of it. Having a fit on being by-passed for an out-of-the ordinary role she wanted, she refuses to attend the premiere of her latest film. Joslyn finds a double for her (Lola\\'s real life sister Rosemary Lane), and Rosemary is made up to play the star at the premiere and the follow-up party. But she attends with Powell (Joslyn wanting someone who doesn\\'t know the real Lola). This leads to Powell knocking down Mowbray when the latter makes a pest of himself. But otherwise the evening is a success, and when the two are together they start finding each other attractive.<br /><br />The complications deal with Lola coming back and slapping Powell in the face, after Mowbray complains he was attacked by Powell (\"and his gang of hoodlums\"). Powell\\'s contract is bought out. Working with photographer turned agent Ted Healey (actually not too bad in this film - he even tries to do a Jolson imitation at one point), the two try to find work, ending up as employees at a hamburger stand run by bad tempered Edgar Kennedy (the number of broken dishes and singing customers in the restaurant give Edgar plenty of time to do his slow burns with gusto). Eventually Powell gets a \"break\" by being hired to be Dupre\\'s singing voice in a rip-off of \"Gone With The Wind\". This leads to the final section of the film, when Rosemary Lane, Herbert, and Healey help give Powell his chance to show it\\'s his voice, not Mowbrays.<br /><br />It\\'s quite a cute and appealing film even now. The worst aspects are due to it\\'s time. Several jokes concerning African-Americans are no longer tolerable (while trying to photograph Powell as he arrives in Hollywood, Healey accidentally photographs a porter, and mentions to Joslyn to watch out, Powell photographs too darkly - get the point?). Also a bit with Curt Bois as a fashion designer for Lola Lane, who is (shall we say) too high strung is not very tolerable either. Herbert\\'s \"hoo-hoo\"ing is a bit much (too much of the time) but it was really popular in 1937. And an incident where Healey nearly gets into a brawl at the premiere (this was one of his last films) reminds people of the tragic, still mysterious end of the comedian in December 1937. But most of the film is quite good, and won\\'t disappoint the viewer in 2008.'\n",
            "Label 3: 1\n"
          ]
        }
      ],
      "source": [
        "# Preview some samples\n",
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(f'Review {i + 1}: {text_batch.numpy()[i]}')\n",
        "        print(f'Label {i + 1}: {label_batch.numpy()[i]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPSe5c29iPkN"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvkDCyDbhMKd"
      },
      "source": [
        "### Standardizating the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YW0u32JKg7vl"
      },
      "outputs": [],
      "source": [
        "# Convert text to lowercase\n",
        "train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_obsbfmihtz",
        "outputId": "ccef3a80-7aff-46e1-dba0-7863e6bb3a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review : b\"nobody said movies had to be realistic did they? i really liked this movie because i remember when i first saw it in junior high. for all the kids who remember the pmrc and albums before there were warning stickers, it's a cool story for all those kids who were part of the mid to late 80's headbanger crowd.\"\n",
            "Label : 1\n",
            "Review : b\"a different look at horror. the styling differences between american and russian films is interesting. however from my american perspective this movie just wasn't that good. the protagonist, marie played by anastasia hille wasn't a pleasant character and i had a hard time identifying with her. she was disagreeable most of the time and confused for much of what little time was left. also too much time was spent in bringing her to the main location of the film. then a long time passed before any real suspense built up. once that happened it seemed volume was used as the main effect which was more annoying than anything else. the concept was more original than most direct-to-video movies and they didn't use sex to make up for a thin plot. all in all i'd recommend it for renting, but not for theater goers.\"\n",
            "Label : 0\n",
            "Review : b'the movie \"atlantis: the lost empire\" is a shining gem in the rubble of films produced by the disney studios recently. parents who have had to sit through \"the jungle book 2\" or even a pokemon movie will surely appreciate this one.<br /><br />the film is one of few to attempt at an original story; previous feature films were merely re tellings of existing stories. films such as \"toy story\", \"finding nemo\", and \"monsters inc.\" all do the same, but it must be noted that all were made by pixar and only distributed by disney. recent films from the disney studios are mostly released direct to video, and are sequels to an existing successful film. the quality of those films is given way to the profitability. a new era started with \"atlantis\" following it were \"mulan\", \"lilo & stitch\", and most recently \"open range\". the writers have created all original story lines instead of the fairy tales of the past.<br /><br />a good portion of the movie is devoted to the quest to find atlantis, a task that has captured the imagination of many for hundreds of years. including that of young milo thatch, voiced by michael j. fox. milo is employed by a museum in washington d.c.. his grandfather was a renowned archaeologist, who had devoted his life to discovering atlantis. this was seen as a waste by his peers, and they wish milo to not follow in his footsteps. after failing to convince the museum board of directors to sponsor his expedition, milo comes home to find a woman in his darkened apartment. she takes him to her employer, a mr. whitmore. whitmore was a close friend of milo\\'s grandfather, and wishes to send milo with a team to locate atlantis. mr. whitmore is very wealth and has paid for the best of everything. the crew that is to accompany him is the same as his grandfathers. the journey is filled with many great obstacles to overcome and is great fun to watch. the viewer finds themselves caught up in if they will reach atlantis. the plot takes an unexpected turn after the discovery atlantis, not just the discovery of people. it is enough to keep the interest of the older audience.<br /><br />the animators have done a wonderful job in then depth of the animation. the movie is very successful in blending traditional animation with computer generated images. a feat not easily achieved, most audiences are quick to notice the difference in the two. the characters are believably human. there are some nice chase type scenes, with lots of action going on. a few lulls are filled with jokes that the children just may not get.<br /><br />the creativity of the writers really shines through. the culture of atlantis is richly developed, including an entire language. the film uses references to atlantis from historical sources, such as plato. the disappearance of atlantis from the world is explained. believable, if by a younger audience, that magic really does exist. the powers of the people of atlantis are not exactly presented as magic, but can best be described in this way.<br /><br />although set in 1914 the level of technology used is unrealistic. the voyage is in a submarine very reminiscent of captain nemo\\'s nautilus, complete with sub pods that fire torpedoes. the giant diggers are driven by steam boilers so they did try for some era technology. the female characters are empowered in a way that women of the age would not have been, even holding roles in leadership. this is not a bad thing. it gives a good role model for my daughter to look to, rather than an all male cast.<br /><br />one reason this film is a favorite of mine over other disney films is that there is not one single song, ever. a tradition that began with the first feature film, \"snow white\", and carried on through to \"the lion king\", almost every disney film is full of upbeat songs. this is great and all, what would the seven dwarfs be without \"hi ho!\"? after the millionth time through it\\'d almost be better without, but this one spares the parent. not once does every single person on the screen suddenly know the words to a song that no one has ever heard before and break out in song. i for one am grateful.<br /><br />the storyline and depth of animation is sure to keep the attention of both parent and child alike. it is a film i am willing to watch again and again with my children.'\n",
            "Label : 1\n"
          ]
        }
      ],
      "source": [
        "# Visualize some samples\n",
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(f'Review : {text_batch.numpy()[i]}')\n",
        "        print(f'Label : {label_batch.numpy()[i]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwurVp6tjWUp"
      },
      "source": [
        "### Tokenizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZhHYjsWVirvn"
      },
      "outputs": [],
      "source": [
        "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
        "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "        word_piece_ds.batch(1000).prefetch(2),\n",
        "        vocabulary_size=vocab_size,\n",
        "        reserved_tokens=reserved_tokens,\n",
        "    )\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvOtSNvLkUEx",
        "outputId": "2fa55165-f272-4f49-8c8f-99092b7fe381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é']\n"
          ]
        }
      ],
      "source": [
        "# Every vocabulary has a few special, reserved tokens : \"[PAD]\" - Padding token, \"[UNK]\" - Unknown token\n",
        "reserved_tokens = [\"[PAD]\", \"[UNK]\"]\n",
        "\n",
        "# Create the tokenizer\n",
        "train_sentences = [element[0] for element in train_ds]\n",
        "vocab = train_word_piece(train_ds, VOCAB_SIZE, reserved_tokens)\n",
        "\n",
        "# Print some tokens\n",
        "print(f'Tokens: {vocab[100:110]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Hy1-i-WYlLTa"
      },
      "outputs": [],
      "source": [
        "# Define the tokenizer\n",
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    lowercase=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13N7jxt5lzJY",
        "outputId": "8a913f14-66d4-4268-ff9c-cfc5f13d2bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence: b\"prot\\xc3\\xa9g\\xc3\\xa9 runs in a linear fashion; expect no fast-paced action, and neither will you find yourself with baited breath because there are simply no seating-on-the-edge moments.<br /><br />there is not much of a crux, so don't expect one either. i would not fault the acting - the show would have been much worst if not for wu's acting which was the film's only saving grace. and, oh that cute little girl too.<br /><br />the humour is at best, weak, and the show must as well pass off as an anti-drug campaign which employs the usual shock-tactic (esp in the scenes with zhang) to tell us stuff that we already know - i.e. drugs break up families, heroin drives you crazy, it is not so easy to wean off, you will fall into a vicious cycle.<br /><br />i know it may seem all a little harsh, but i feel that the show is far from seamless and somewhat patchy (*spoiler alert*: take for example when andy lau got brought to the police station: what? we were just told 'oh we have all the tapes and evidence against you since 1997', and that is how he got caught. nope, no chasing-car action, just a jump-of-scene, which kind of undermined wu's role as an undercover in the first place.) i suspect the lack of creativity is attributed to the fact that it is after all, a production of mediacorp raintree - a singaporean production film company.\"\n",
            "Tokens: [ 3732   398  3469 12865  1315   144    40  6915  1794    28   669   192\n",
            "   843    14  2046   343    13   138  1222   213   155   306   774   151\n",
            "  9725   257  2978   220   173   158   472   192  2454   239    14   154\n",
            "    14   137    14  1469   523    15    29   142    16    31    29   142\n",
            "    16    31   173   141   156   207   139    40    42 11751  1214    13\n",
            "   170   223     8    59   669   162   483    15    48   194   156  2405\n",
            "   137   246    14   137   255   194   160   210   207   387   180   156\n",
            "   149  8510     8    58   246   195   147   137   153     8    58   197\n",
            "  2065  1816    15   138    13   579   146  1187   250   377   231    15\n",
            "    29   142    16    31    29   142    16    31   137  1470   141   165\n",
            "   251    13   953    13   138   137   255   345   148   205  1486   260\n",
            "   148   168  1377    14  1586  6059   195 11186   137   779  1678    14\n",
            "    59 10718     9 13529   144   137   276   151 12052    10   140   519\n",
            "   317   675   146   202   606   256    14    48    15    44    15  1850\n",
            "  1143   189  2344    13 11213  3357   155  1078    13   143   141   156\n",
            "   170   911   140   202   771   260    13   155   213   925   217    40\n",
            "  4431  7832    15    29   142    16    31    29   142    16    31    48\n",
            "   256   143   338   448   163    40   250  2793    13   152    48   370\n",
            "   146   137   255   141   367   171 14257   138   812 10633   292     9\n",
            "    11  1491  4658    11    27   334   149   603   186  1927  1247   978\n",
            "   327  1019   140   137   712  1940    27   181    32   202   204   176\n",
            "   715     8   579   202   160   163   137  6192   138  2615   582   155\n",
            "   373  5448     8    13   138   146   141   221   157   327  1205    15\n",
            "  6826    13   192  3488    14   663   343    13   176    40  1953    14\n",
            "   139    14   271    13   195   380   139   619 12439  8510     8    58\n",
            "   357   148   168  9890   144   137   216   408    15    10    48  2000\n",
            "   137   711   139  5279   141 11125   140   137   328   146   143   141\n",
            "   234   163    13    40   503   139  1947 12062   895  2538  9272   314\n",
            "    14    40  2167  5915  4602   771   503   153  1291    15     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "Recovered text after detokenizing:  tf.Tensor(b\"prot\\xc3\\xa9g\\xc3\\xa9 runs in a linear fashion ; expect no fast - paced action , and neither will you find yourself with baited breath because there are simply no seating - on - the - edge moments . < br / > < br / > there is not much of a crux , so don ' t expect one either . i would not fault the acting - the show would have been much worst if not for wu ' s acting which was the film ' s only saving grace . and , oh that cute little girl too . < br / > < br / > the humour is at best , weak , and the show must as well pass off as an anti - drug campaign which employs the usual shock - tactic ( esp in the scenes with zhang ) to tell us stuff that we already know - i . e . drugs break up families , heroin drives you crazy , it is not so easy to wean off , you will fall into a vicious cycle . < br / > < br / > i know it may seem all a little harsh , but i feel that the show is far from seamless and somewhat patchy ( * spoiler alert * : take for example when andy lau got brought to the police station : what ? we were just told ' oh we have all the tapes and evidence against you since 1997 ' , and that is how he got caught . nope , no chasing - car action , just a jump - of - scene , which kind of undermined wu ' s role as an undercover in the first place . ) i suspect the lack of creativity is attributed to the fact that it is after all , a production of mediacorp raintree - a singaporean production film company . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Let's try and tokenize a sample from our dataset\n",
        "input_sentence_ex = train_ds.take(1).get_single_element()[0][0]\n",
        "input_tokens_ex = tokenizer(input_sentence_ex)\n",
        "\n",
        "print(f'Input sentence: {input_sentence_ex}')\n",
        "print(f'Tokens: {input_tokens_ex}')\n",
        "print(f'Recovered text after detokenizing: ', tokenizer.detokenize(input_tokens_ex))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gINe34sEnO84"
      },
      "source": [
        "### Formatting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I1Hzu_YVnTvs"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text\n",
        "def format_dataset(sentence, label):\n",
        "    sentence = tokenizer(sentence)\n",
        "    return ({'input_ids': sentence}, label)\n",
        "\n",
        "def make_dataset_(dataset):\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(512).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset_(train_ds)\n",
        "val_ds = make_dataset_(val_ds)\n",
        "test_ds = make_dataset_(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJucEuYZpf5w"
      },
      "source": [
        "## Building the FNet model\n",
        "![](https://blog-assets.freshworks.com/freshworks/wp-content/uploads/2023/10/25070756/i-attention-is-not_inline-1_812x400.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TIB_JaZpYrK",
        "outputId": "7aee48fc-caf8-4e8b-e506-b89b1a8af06b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'f_net_encoder' (of type FNetEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "input_ids = keras.Input(shape=(None,), dtype='int64', name='input_ids')\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(x)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "fnet_classifier = keras.Model(inputs=input_ids, outputs=outputs, name='fnet_classifier')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QWMKJFQrhQK"
      },
      "source": [
        "## Training our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "3oVh_3g5rdEL",
        "outputId": "0da5c78a-df9f-4fe2-a60e-2135a85adec2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"fnet_classifier\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fnet_classifier\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,985,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ f_net_encoder (\u001b[38;5;33mFNetEncoder\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m132,224\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ f_net_encoder_1 (\u001b[38;5;33mFNetEncoder\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m132,224\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ f_net_encoder_2 (\u001b[38;5;33mFNetEncoder\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m132,224\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,985,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ f_net_encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FNetEncoder</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">132,224</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ f_net_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FNetEncoder</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">132,224</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ f_net_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FNetEncoder</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">132,224</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,147,013\u001b[0m (27.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,147,013</span> (27.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,382,337\u001b[0m (9.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,382,337</span> (9.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,764,676\u001b[0m (18.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,764,676</span> (18.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 66ms/step - accuracy: 0.9800 - loss: 0.0564 - val_accuracy: 0.8500 - val_loss: 0.5483\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.9839 - loss: 0.0449 - val_accuracy: 0.8604 - val_loss: 0.5723\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 0.9938 - loss: 0.0196 - val_accuracy: 0.8622 - val_loss: 0.5803\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 0.8510 - val_loss: 0.6902\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.9984 - loss: 0.0079 - val_accuracy: 0.8438 - val_loss: 0.7566\n"
          ]
        }
      ],
      "source": [
        "fnet_classifier.summary()\n",
        "\n",
        "fnet_classifier.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = fnet_classifier.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NFeDkZLDsETD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67de0a6c-54ac-406c-ec50-de84e6b41f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8309 - loss: 0.8576\n",
            "Test accuracy: 0.8307600021362305\n"
          ]
        }
      ],
      "source": [
        "# Calculate the test accuracy.\n",
        "test_loss, test_acc = fnet_classifier.evaluate(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IytPnqhksyd6"
      },
      "source": [
        "## Comparison with Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSE9SE66s8X_"
      },
      "outputs": [],
      "source": [
        "# We set the number of heads to 2 for Transformer classifier model\n",
        "NUM_HEADS = 2\n",
        "\n",
        "input_ids = keras.Input(shape=(None,), dtype='int64', name='input_ids')\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.TransformerEncoder(intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS)(x)\n",
        "x = keras_nlp.layers.TransformerEncoder(intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS)(x)\n",
        "x = keras_nlp.layers.TransformerEncoder(intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS)(x)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "transformer_classifier = keras.Model(inputs=input_ids, outputs=outputs, name='transformer_classifier')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gcqFWNs3vH3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "9262c5f2-2aab-4ece-b723-cb9d17224c90"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_classifier\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer_classifier\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ token_and_position_embed… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,985,536</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbeddi…</span> │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ token_and_position_em… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ transformer_encoder_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_encoder_2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ token_and_position_embed… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │      \u001b[38;5;34m1,985,536\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbeddi…\u001b[0m │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m198,272\u001b[0m │ token_and_position_em… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m198,272\u001b[0m │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m198,272\u001b[0m │ transformer_encoder_1… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ transformer_encoder_2… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,481</span> (9.84 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,580,481\u001b[0m (9.84 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,481</span> (9.84 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,580,481\u001b[0m (9.84 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 140ms/step - accuracy: 0.6644 - loss: 0.6374 - val_accuracy: 0.8788 - val_loss: 0.2999\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - accuracy: 0.9099 - loss: 0.2343 - val_accuracy: 0.8856 - val_loss: 0.3019\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 101ms/step - accuracy: 0.9423 - loss: 0.1549 - val_accuracy: 0.8832 - val_loss: 0.3421\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 110ms/step - accuracy: 0.9599 - loss: 0.1131 - val_accuracy: 0.8556 - val_loss: 0.4909\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 103ms/step - accuracy: 0.9654 - loss: 0.0918 - val_accuracy: 0.8750 - val_loss: 0.4979\n"
          ]
        }
      ],
      "source": [
        "transformer_classifier.summary()\n",
        "\n",
        "transformer_classifier.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = transformer_classifier.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VA0VnyQovnQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5606960d-941f-4260-bfba-e82bb2af8a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.8478 - loss: 0.6000\n",
            "Test accuracy: 0.8485599756240845\n"
          ]
        }
      ],
      "source": [
        "# Calculate the test accuracy.\n",
        "test_loss, test_acc = transformer_classifier.evaluate(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqMtt8LqwcoB"
      },
      "source": [
        "## Let's make a table and compare the two models\n",
        "accuracy: 0.9984\n",
        " val_accuracy: 0.8438\n",
        "  Total params: 7,147,013\n",
        "\n",
        "\n",
        "\n",
        "|                         | **FNet Classifier** | **Transformer Classifier** |\n",
        "|:-----------------------:|:-------------------:|:--------------------------:|\n",
        "|    **Training Time**    |      98 seconds     |         196 seconds        |\n",
        "|    **Train Accuracy**   |        99.84 %       |           96.45%           |\n",
        "| **Validation Accuracy** |        84.34%       |           87.50%           |\n",
        "|    **Test Accuracy**    |        83.07%       |           84.85%           |\n",
        "|       **#Params**       |      2,321,921      |          2,580,481         |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOu1y3kw2Sqtx17yjGUao8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}