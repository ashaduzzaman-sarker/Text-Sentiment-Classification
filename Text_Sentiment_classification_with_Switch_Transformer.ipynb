{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOflX5CtATKYCX0usXg++Tl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashaduzzaman-sarker/Text-classification-Sentiment-Analysis/blob/main/Text_Sentiment_classification_with_Switch_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a Switch Transformer for text classification.\n",
        "\n",
        "## Introduction\n",
        "The [Swiss Transformer](https://doi.org/10.48550/arXiv.2101.03961) is a variant of the transformer architecture designed for improved efficiency and performance. Here’s a brief explanation:\n",
        "\n",
        "- **Switch Transformer Overview:** A variant of the Transformer model designed for text classification.\n",
        "  \n",
        "- **Key Modification:** Replaces the standard feedforward network (FFN) layer in Transformers with a Mixture of Expert (MoE) routing layer.\n",
        "  \n",
        "- **MoE Layer:** Involves multiple experts (sub-networks) that independently process tokens, enabling an increase in model size without proportional increases in computation for each example.\n",
        "  \n",
        "- **Parallelism Requirement:** Efficient training requires data and model parallelism, with experts running on separate accelerators simultaneously.\n",
        "\n",
        "- **Distributed Training:** The full implementation, as described in the original paper, uses TensorFlow Mesh for distributed training, though the provided example is a simpler, non-distributed version for demonstration purposes.\n",
        "\n",
        "[Mixture of Experts Explained...](https://huggingface.co/blog/moe)\n",
        "\n",
        "![](https://production-media.paperswithcode.com/methods/a316fa39-5d0e-4058-88a0-31007cbbb44a.png)"
      ],
      "metadata": {
        "id": "9NP7PYJ8DQEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n"
      ],
      "metadata": {
        "id": "wgiTdwHuEF6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G6pjpGVxDAgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fd129c89-d5ea-4870-c401-dd3899251446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "VuPR4-9zEaHo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and prepare Dataset"
      ],
      "metadata": {
        "id": "zZkzpz-kEhYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000 # Only first 20k words considered\n",
        "num_tokens_per_example = 200 # Only first 200 words of each movie review\n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNQ___qAFFut",
        "outputId": "ab6a9f34-85fa-407d-f13e-4f6b372ad855"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "25000 Training sequences\n",
            "25000 Validation sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = keras.utils.pad_sequences(x_train, maxlen=num_tokens_per_example)\n",
        "x_val = keras.utils.pad_sequences(x_val, maxlen=num_tokens_per_example)"
      ],
      "metadata": {
        "id": "vxjdCsBoG3VY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Hyperparameter"
      ],
      "metadata": {
        "id": "nsyFHWymHFB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "num_experts = 10  # Number of experts used in MoE\n",
        "batch_size = 50  # Batch size\n",
        "learning_rate = 0.001  # Learning rate\n",
        "num_epochs = 5  # Number of epochs\n",
        "dropout_rate = 0.25  # Dropout rate\n",
        "num_tokens_per_batch = (\n",
        "    batch_size * num_tokens_per_example\n",
        ")  # Total number of tokens per batch\n",
        "\n",
        "print(f'Number of tokens per batch: {num_tokens_per_batch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjGpm3W6HEuF",
        "outputId": "a65eb55a-dabd-4e4e-ec6b-88cd960a0e71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens per batch: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Token & Position embedding layer"
      ],
      "metadata": {
        "id": "sj6zS0f2HsRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "  def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "    super().__init__()\n",
        "    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "  def call(self, x):\n",
        "    maxlen = ops.shape(x)[-1]\n",
        "    positions = ops.arange(start=0, stop=maxlen, step=1)\n",
        "    positions = self.pos_emb(positions)\n",
        "    x = self.token_emb(x)\n",
        "    return x + positions"
      ],
      "metadata": {
        "id": "2viv3TQwHAll"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement the feed forward network\n",
        "\n",
        "In Switch Transformer this is use as Mixture of Experts (MoE)\n",
        "\n",
        "![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/moe/01_moe_layer.png)"
      ],
      "metadata": {
        "id": "Cd2S3eV2IiKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feedforward_network(ff_dim, embed_dim, name=None):\n",
        "  return keras.Sequential(\n",
        "      [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),], name=name\n",
        "  )"
      ],
      "metadata": {
        "id": "SCP3WhSwIgJP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement the Load-balances loss\n",
        "\n",
        "**Load-balanced loss** is a technique used in Mixture of Experts (MoE) models, such as the Switch Transformer, to ensure that the computational load is evenly distributed across different experts (sub-networks) during training"
      ],
      "metadata": {
        "id": "CXFs5LDHJf30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_balanced_loss(router_probs, expert_mask):\n",
        "    # Get the number of experts from the last dimension of the expert mask\n",
        "    num_experts = ops.shape(expert_mask)[-1]\n",
        "\n",
        "    # Calculate the density, which is the mean of the expert mask across the batch dimension\n",
        "    # This represents the actual load distribution across the experts\n",
        "    density = ops.mean(expert_mask, axis=0)\n",
        "\n",
        "    # Calculate the density proxy, which is the mean of the router probabilities across the batch\n",
        "    # This represents the intended or predicted load distribution across the experts\n",
        "    density_proxy = ops.mean(router_probs, axis=0)\n",
        "\n",
        "    # Compute the load-balanced loss\n",
        "    # The loss is calculated by taking the element-wise product of density and density proxy,\n",
        "    # followed by averaging and scaling by the square of the number of experts\n",
        "    loss = ops.mean(density_proxy * density) * ops.cast((num_experts ** 2), 'float32')\n",
        "\n",
        "    # Return the calculated load-balanced loss\n",
        "    return loss"
      ],
      "metadata": {
        "id": "asYMsRawJfUn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement the router as a layer"
      ],
      "metadata": {
        "id": "6pSCPui4LZ05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Router(layers.Layer):\n",
        "    def __init__(self, num_experts, expert_capacity):\n",
        "        self.num_experts = num_experts  # Number of experts available\n",
        "        self.route = layers.Dense(units=num_experts)  # Dense layer to produce routing logits\n",
        "        self.expert_capacity = expert_capacity  # Maximum capacity for each expert\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        # inputs shape: [tokens_per_batch, embed_dim]\n",
        "        # router_logits shape: [tokens_per_batch, num_experts]\n",
        "        router_logits = self.route(inputs)  # Compute routing logits for each token\n",
        "\n",
        "        if training:\n",
        "            # Add random noise during training to encourage exploration of different experts\n",
        "            router_logits += keras.random.uniform(\n",
        "                shape=router_logits.shape,\n",
        "                minval=0.9,\n",
        "                maxval=1.1,\n",
        "            )\n",
        "\n",
        "        # Convert logits to probabilities using softmax\n",
        "        router_probs = keras.activations.softmax(router_logits, axis=-1)\n",
        "\n",
        "        # Select the top expert for each token\n",
        "        expert_gate, expert_index = ops.top_k(router_probs, k=1)\n",
        "\n",
        "        # Create a binary mask indicating the selected expert for each token\n",
        "        expert_mask = ops.one_hot(expert_index, self.num_experts)\n",
        "\n",
        "        # Calculate the auxiliary load-balancing loss to distribute the load evenly across experts\n",
        "        aux_loss = load_balanced_loss(router_probs, expert_mask)\n",
        "        self.add_loss(aux_loss)  # Add the auxiliary loss to the layer's loss\n",
        "\n",
        "        # Calculate the position of each token within its selected expert\n",
        "        position_in_expert = ops.cast(ops.cumsum(expert_mask, axis=0) * expert_mask, 'int32')\n",
        "\n",
        "        # Mask out tokens that exceed the expert's capacity\n",
        "        expert_mask *= ops.cast(ops.less(ops.cast(position_in_expert, 'int32'), self.expert_capacity), 'float32')\n",
        "\n",
        "        # Flatten the expert mask to determine if a token was assigned to an expert\n",
        "        expert_mask_flat = ops.sum(expert_mask, axis=-1)\n",
        "\n",
        "        # Adjust the gating values by the flattened expert mask\n",
        "        expert_gate *= expert_mask_flat\n",
        "\n",
        "        # Combine the inputs, gating values, and position information into a single tensor\n",
        "        combined_tensor = ops.expand_dims(\n",
        "            expert_gate\n",
        "            * expert_mask_flat\n",
        "            * ops.squeeze(ops.one_hot(expert_index, self.num_experts), 1),\n",
        "            -1,\n",
        "        ) * ops.squeeze(ops.one_hot(position_in_expert, self.expert_capacity), 1)\n",
        "\n",
        "        # Convert the combined tensor to a float32 tensor\n",
        "        dispatch_tensor = ops.cast(combined_tensor, 'float32')\n",
        "\n",
        "        return dispatch_tensor, combined_tensor  # Return the dispatch and combined tensors\n"
      ],
      "metadata": {
        "id": "UWn0U7FBLb7p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement a Switch layer"
      ],
      "metadata": {
        "id": "mnHyCHTiPzFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Switch(layers.Layer):\n",
        "  def __init__(\n",
        "      self,\n",
        "      num_experts,\n",
        "      embed_dim,\n",
        "      ff_dim,\n",
        "      num_tokens_per_batch,\n",
        "      capacity_factor=1,\n",
        "  ):\n",
        "      self.num_experts = num_experts\n",
        "      self.embed_dim = embed_dim\n",
        "      self.experts = [\n",
        "          create_feedforward_network(ff_dim, embed_dim) for _ in range(num_experts)\n",
        "      ]\n",
        "      self.expert_capacity = num_tokens_per_batch // self.num_experts\n",
        "      self.router = Router(self.num_experts, self.expert_capacity)\n",
        "      super().__init__()\n",
        "\n",
        "  def call(self, inputs):\n",
        "      batch_size = ops.shape(inputs)[0]\n",
        "      num_tokens_per_example = ops.shape(inputs)[1]\n",
        "\n",
        "      # inputs shape: [num_tokens_per_batch, embed_dim]\n",
        "      inputs = ops.reshape(inputs, [num_tokens_per_batch, self.embed_dim])\n",
        "\n",
        "      # dispatch_tensor shape: [expert_capacity, num_experts, tokens_per_batch]\n",
        "      # compute_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
        "      dispatch_tensor, combine_tensor = self.router(inputs)\n",
        "\n",
        "      # expert_inputs shape: [num_experts, expert_capacity, embed_dim]\n",
        "      expert_inputs = ops.einsum('ab,acd->cdb', inputs, dispatch_tensor)\n",
        "      expert_inputs = ops.reshape(expert_inputs, [self.num_experts, self.expert_capacity, self.embed_dim])\n",
        "\n",
        "      # Dispatch to experts\n",
        "      expert_input_list = ops.unstack(expert_inputs, axis=0)\n",
        "      expert_output_list = [\n",
        "          self.experts[idx](expert_input)\n",
        "          for idx, expert_input in enumerate(expert_input_list)\n",
        "      ]\n",
        "\n",
        "      # expert_outputs shape: [expert_capacity, num_experts, embed_dim]\n",
        "      expert_outputs = ops.stack(expert_output_list, axis=1)\n",
        "\n",
        "      # expert_outputs_combined shape: [tokens_per_batch, embed_dim]\n",
        "      expert_outputs_combined = ops.einsum(\n",
        "          'abc,xba->xc', expert_outputs, combine_tensor\n",
        "      )\n",
        "\n",
        "      # output shape: [batch_size, num_tokens_per_example, embed_dim]\n",
        "      outputs = ops.reshape(\n",
        "          expert_outputs_combined,\n",
        "          [batch_size, num_tokens_per_example, self.embed_dim],\n",
        "      )\n",
        "      return outputs"
      ],
      "metadata": {
        "id": "v7TWCmhNPx-0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement a Transformer block layer"
      ],
      "metadata": {
        "id": "_GrwoQBQP3_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "  def __init__(self, embed_dim, num_heads, ffn, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "    # ffn can be either a standard feedforward network or a switch layer with a Mixture of Experts\n",
        "    self.ffn = ffn\n",
        "    self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.dropout1 = layers.Dropout(dropout_rate)\n",
        "    self.dropout2 = layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    attn_output = self.att(inputs, inputs)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(inputs + attn_output)\n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "crywAeOKX4LC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement the classifier\n",
        "\n",
        "- **TransformerBlock Layer**: Outputs one vector for each time step in the input sequence.\n",
        "- **Mean Pooling**: Takes the average of all vectors across time steps.\n",
        "- **Feedforward Network**: Applied on the mean-pooled vector to classify the text."
      ],
      "metadata": {
        "id": "8GLcsxZzP81b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classifier():\n",
        "  switch = Switch(num_experts, embed_dim, ff_dim, num_tokens_per_batch)\n",
        "  transformer_block = TransformerBlock(embed_dim // num_heads, num_heads, switch)\n",
        "\n",
        "  inputs = layers.Input(shape=(num_tokens_per_example,))\n",
        "  embedding_layer = TokenAndPositionEmbedding(\n",
        "      num_tokens_per_example, vocab_size, embed_dim\n",
        "  )\n",
        "  x = embedding_layer(inputs)\n",
        "  x = transformer_block(x)\n",
        "  x = layers.GlobalAveragePooling1D()(x)\n",
        "  x = layers.Dropout(dropout_rate)(x)\n",
        "  x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(dropout_rate)(x)\n",
        "  outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "  classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return classifier"
      ],
      "metadata": {
        "id": "AqMdo_7PY6Aq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate the model"
      ],
      "metadata": {
        "id": "S16nC35MP_pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(classifier):\n",
        "  classifier.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate),\n",
        "      loss=\"sparse_categorical_crossentropy\",\n",
        "      metrics=[\"accuracy\"],\n",
        "  )\n",
        "  history = classifier.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size=batch_size,\n",
        "      epochs=num_epochs,\n",
        "      validation_data=(x_val, y_val),\n",
        "  )\n",
        "  return history\n",
        "\n",
        "classifier = create_classifier()\n",
        "run_experiment(classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ZjBlUJaBSD",
        "outputId": "4c5735f9-7c99-4fd2-f8fa-adfcc4aee4dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2534s\u001b[0m 5s/step - accuracy: 0.7058 - loss: 1.5540 - val_accuracy: 0.8753 - val_loss: 1.2915\n",
            "Epoch 2/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2534s\u001b[0m 5s/step - accuracy: 0.9215 - loss: 1.2154 - val_accuracy: 0.8691 - val_loss: 1.3053\n",
            "Epoch 3/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2560s\u001b[0m 5s/step - accuracy: 0.9584 - loss: 1.1268 - val_accuracy: 0.8654 - val_loss: 1.3515\n",
            "Epoch 4/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2602s\u001b[0m 5s/step - accuracy: 0.9738 - loss: 1.0825 - val_accuracy: 0.8545 - val_loss: 1.5022\n",
            "Epoch 5/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2561s\u001b[0m 5s/step - accuracy: 0.9833 - loss: 1.0536 - val_accuracy: 0.8486 - val_loss: 1.6242\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d3553321de0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}