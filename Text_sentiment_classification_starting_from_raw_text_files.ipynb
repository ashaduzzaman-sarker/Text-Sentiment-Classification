{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text sentiment classification starting from raw text files."
      ],
      "metadata": {
        "id": "LtGVNZnBP594"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "w5vyVnVHaxfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "G2_i8ULiPo0e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data: IMDB movie review sentiment classification"
      ],
      "metadata": {
        "id": "rB-O1a3GbMxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSR3-FofbSa2",
        "outputId": "bfbe911e-e4f8-4437-fd96-5a4a743b963b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  3118k      0  0:00:26  0:00:26 --:--:-- 3250k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The aclImdb folder contains a train and test subfolder\n",
        "!ls aclImdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RvnRdPYbWrK",
        "outputId": "5ab79da1-1bd4-4c40-acac-086355a9c8cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMRGxOObh3F",
        "outputId": "574581db-2b52-47f1-96e7-17052b3332ad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm69rtdtbuZh",
        "outputId": "6efbc3e5-f918-4e36-c9df-fdf4df2093a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  unsup  unsupBow.feat  urls_neg.txt  urls_pos.txt  urls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The aclImdb/train/pos and aclImdb/train/neg folders contain text files (either positive or negative review)\n",
        "!cat aclImdb/train/pos/11558_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd2r81H1bxrp",
        "outputId": "06381fd4-bffe-49d6-8f81-2f091c042954"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"The Odd Couple\" is one of those movies that far surpasses its reputation. People all know it, they hum the theme song, they complain of living with a sloppy \"Oscar\" or a fastidious \"Felix\"...but they're under-selling the film without knowing it. This isn't just about a neat guy living with a sloppy guy; it's a portrait of two friends helping each other through the agony of divorce. It's also damn funny from start to finish, but it's the kind of comedy that arises from realistic, stressful, and just plain awful situations. So, some viewers have actually found the film to be a bit uncomfortable, but I think its verisimilitude is its strength. Besides, Matthau's bulldog face just cracks me up! My favorite comedy, by a country mile."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/neg/11008_1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_sCOiTfb_az",
        "outputId": "0e9149b9-b994-4611-9844-321aa296d635"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I bought this at tower records after seeing the info-mercial about fifteen hundred times on comedy central. I was actually really looking forward to watching this. My god where did i go wrong? Now before i give my review let me just say that i am a person who can pretty much find the good in all movies, hell i own over 1,500 dvd's! With that said, the underground comedy movie ranks up there with the worst film i have EVER seen. I tried to give it a chance, but not only was it not funny. It had no point, did not offend what-so-ever and was all around stupid. God who in their right mind thought these pieces of crap were funny? this is going right to the bottom of the bin..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping pos and neg subfolders only (remove unsup)\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "SR4FnXOdcfbe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spliting the data"
      ],
      "metadata": {
        "id": "nk23QtqPdan7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "\"\"\"\n",
        "The utility `keras.utils.text_dataset_from_directory` to generate a labeled\n",
        "tf.data.Dataset object from a set of text files on disk filed into class-specific folders\n",
        "\"\"\"\n",
        "raw_train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        ")\n",
        "\n",
        "raw_val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=133\n",
        ")\n",
        "\n",
        "raw_test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "\n",
        "print(f'Number of batches in raw_train_ds: {raw_train_ds.cardinality()}')\n",
        "print(f'Number of batches in raw_val_ds: {raw_val_ds.cardinality()}')\n",
        "print(f'Number of batches in raw_test_ds: {raw_test_ds.cardinality()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNEf0ViYc8jo",
        "outputId": "004f2360-c994-4d28-af4f-9afdf2eaf1dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Number of batches in raw_train_ds: 625\n",
            "Number of batches in raw_val_ds: 157\n",
            "Number of batches in raw_test_ds: 782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview some samples\n",
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(f'Review {i + 1}: {text_batch.numpy()[i]}')\n",
        "        print(f'Label {i + 1}: {label_batch.numpy()[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOsBEmaTedCE",
        "outputId": "ca926d99-b4c7-42b7-dd21-9fdf878aa5b5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 1: b'I am very disappointed with \"K-911.\" The original \"good\" quality of \"K-9\" doesn\\'t exist any more. This is more like a sitcom! Some of casts from original movie returned and got some of my memory back. The captain of Dooley now loves to hit him like a scene from old comedy show. That was crazy. What\\'s the deal with the change of Police? It seems like they are now LAPD! Not San Diego PD. It is a completely different movie from \"'\n",
            "Label 1: 0\n",
            "Review 2: b\"Giallo fans, seek out this rare film. It is well written, and full of all sorts of the usual low lifes that populate these films. I don't want to give anything away, so I wont even say anything about the plot. The whole movie creates a very bizarre atmosphere, and you don't know what to expect or who to suspect. Recommended! The only place I've seen to get this film in english is from European Trash Cinema, for $15.\"\n",
            "Label 2: 1\n",
            "Review 3: b\"Terry Gilliam's and David Peoples' teamed up to create one of the most intelligent and creative science fiction movies of the '90's. People's proved a screenplay with bizarre twists and fantastic ideas about the nature of time \\xc2\\x97 I especially love the idea one can't change the past; it's a nice counterpoint to so many time-travelling movies which say otherwise \\xc2\\x97 biological holocausts and the thin line between sanity and madness. Gilliam visualized his ideas with unique quirkiness, perfection and originality.<br /><br />The story itself is engaging: one man, James Cole (played by Bruce Willis in a heart-warming performance) travels several decades to the past to retrieve information about a virus that's wiped out mankind and left only a few survivors alive living underground: with the information he'll collect, scientists hope to find a cure so everyone in the future can return to the surface. But because their time-travelling technology isn't perfect, he ends up being sent towards different other pasts and complicating things. And from that a brilliant science fiction thriller with shades of film noir ensues as the multiple pieces of a huge jigsaw start fitting together to form a bizarre narrative involving animal right activists, end of the millennium paranoia, biological weapons, the perception of reality, and the definition of sanity. With such a complex movie, it was easy for Gilliam and Peoples to create a mess, but instead Twelve Monkeys is a thought-provoking narrative which will please those who like to be challenged and have patience to appreciate some crazy ideas.<br /><br />I watched this movie once around 10 years ago. It marked me a lot: I remember still thinking about many days after-wards; for my young mind this seemed quite mind-blowing and it was one of the first movies to make me appreciate cinema as something serious and important. I've re-watched this movie a few days ago on DVD and it's better than I remembered it. Brad Pitt still steals all the scenes he's in, playing Jeffrey Goines \\xc2\\x97 almost a prelude to his Tyler Durden character in Fight Club \\xc2\\x97 a rich kid with some anarchist/non-conformist ideas who's also crazy and, according to Cole, perhaps responsible for the virus. The scenes between Jeffrey and Cole in the madhouse are the best in the movie, Pitt's eyes, voice and quirky mannerisms convince you he's really a crazy guy locked in a warped logic only he understands. Pitt's Oscar nomination was well deserved! Surprising was also Bruce Willis' performance: his I didn't remember very well, but it's beautiful and full of sensibility; he plays a man who spent almost all his life underground, and when he comes to the past you'll share his childish fascination with something as simple as breathing the fresh air of the morning or watching the sun go up. Cole is a rather ambiguous character, Peoples' tried to imbue some darkness in him, and he does other disturbing things to other people and to himself: the scene where he removes his own teeth reveals how far his dementia has gone unchecked. Ironically Cole didn't start as a crazy character, but when he starts warning everyone about the end of the world, he's considered mad and convinced it's all in his mind, until he arrives at a point when he can't distinguish past from future, reality from fiction. Willis spends a lot of time looking confused and insecure, and it works perfectly. One of the fun twists in the narrative is when Cole's shrink, Dr. Kathryn Railly, finds undeniable proof he's really from the future and now has to convince him again of his mission to save the world. The screenplay is full with weird twists like this and it keeps the movie in a fast pace. Their relationship is also well-handed, although perhaps a bit compressed for time's sake. But I enjoyed watching Cole and Railly falling in love and trying to escape the authority of the future to live a peaceful life in the past. But then things end in a tragic/bittersweet climax at an airport, wrapping all the pieces together, which will blow many minds away.<br /><br />There are two great endings in this movie, a twist in the sense of Se7en or Fight Club, and a more intimate ending where Railly is crouching next to Cole who's just been shot and looking around for a younger James Cole who's witnessing his future self die; the two share a brief look, and she smiles at him. The twist is brilliant, but I prefer this ending for emotional impact. Madeleine Stowe is very good playing Dr. Railly, she drew many different emotions from me in her performance. The movie is filled with a sense of fatalism with the idea the past can't be changed: this movie shows that in a terrifying way. It reminds me of Chinatown in that sense, the way Jake Gittes messes everything up the more he tries to help. Railly's character shares that fatalism, the more she tries to help Cole \\xc2\\x97 first dealing with his 'madness' then helping him in his mission \\xc2\\x97 the more they're sucked into tragedy.<br /><br />The twist ends with a hopeful note, though, with the feeling Cole's mission hasn't been in vain. Twelve Monkeys is a great movie to watch if one wants to be entertained; it's not supposed to be art, although it's more artists than many artistic movies. It's an unpretentious movie where all elements, from music to editing to costume design, etc., came together beautifully to produce a modern cinema masterpiece.\"\n",
            "Label 3: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "xQHgfwddfTyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's remove <br /> tags\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Create a custom standardization function\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "    )\n",
        "\n",
        "# Model constantans\n",
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500\n",
        "\n",
        "# Instantiate our text vectorization layer\n",
        "vectorize_layer = keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "# Make a text only dataset (No labels)\n",
        "text_ds = raw_train_ds.map(lambda x, y: x)\n",
        "\n",
        "# Let's call adapt to build the vocabulary\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "eBY24D--fNqQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize the Data"
      ],
      "metadata": {
        "id": "-9DczpRbi4cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply it to the text dataset\n",
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "# Vectorize the data\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# async prefetching/buffering\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "wvL1X_4ziGlQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the simple 1D convnet Model"
      ],
      "metadata": {
        "id": "aduMMpbmjaX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A integer input for vocab indices\n",
        "inputs = keras.Input(shape=(None,), dtype='int64')\n",
        "\n",
        "# Add a layer to map vocab indices into a space of dimentionality 'embedding_dim'\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Build Conv1d with global max pooling\n",
        "x = layers.Conv1D(128, 7, padding='valid', activation='relu', strides=3)(x)\n",
        "x = layers.Conv1D(128, 7, padding='valid', activation='relu', strides=3)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# Add a layer that tranks the features\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Final\n",
        "predictions = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
        "\n",
        "model = keras.Model(inputs, predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wSPIIMjejZGO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "YeN3p39bkkuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "# Fit the model with train and validation datasets\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ggoF1zkidC",
        "outputId": "5309b95e-560e-4094-9733-eb9f0f133bca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 131s 206ms/step - loss: 0.4718 - accuracy: 0.7398 - val_loss: 0.2437 - val_accuracy: 0.9072\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 137s 219ms/step - loss: 0.2166 - accuracy: 0.9172 - val_loss: 0.1287 - val_accuracy: 0.9554\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 122s 195ms/step - loss: 0.1159 - accuracy: 0.9561 - val_loss: 0.1435 - val_accuracy: 0.9536\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 111s 178ms/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.2339 - val_accuracy: 0.9304\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 107s 171ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.1617 - val_accuracy: 0.9626\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 104s 167ms/step - loss: 0.0309 - accuracy: 0.9890 - val_loss: 0.2130 - val_accuracy: 0.9530\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 107s 172ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.1838 - val_accuracy: 0.9614\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 108s 173ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 0.2161 - val_accuracy: 0.9576\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 108s 173ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.2404 - val_accuracy: 0.9564\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 107s 171ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.1824 - val_accuracy: 0.9712\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78a5acb344f0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model on test dataset"
      ],
      "metadata": {
        "id": "6aW5usiek4EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7Krm3aIk1FJ",
        "outputId": "4617cd94-9ded-4308-e1a8-41c60546ba1b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 32s 40ms/step - loss: 0.8894 - accuracy: 0.8584\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8893537521362305, 0.8583999872207642]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End-to_end Model\n",
        "- Capable of preprocessing raw strings\n",
        "- Create a new model with trained weights of above model"
      ],
      "metadata": {
        "id": "7W2YZrP2k_Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A string input\n",
        "inputs = keras.Input(shape=(1, ), dtype='string')\n",
        "\n",
        "# Turn strings into vocab indices\n",
        "indices = vectorize_layer(inputs)\n",
        "\n",
        "# Turn vocab indices into predictions\n",
        "outputs = model(indices)\n",
        "\n",
        "# End-to-end model\n",
        "end_to_end_model = keras.Model(inputs, outputs)\n",
        "end_to_end_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Test it with 'raw_test_ds'\n",
        "end_to_end_model.evaluate(raw_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzzyWlOolgcV",
        "outputId": "cf4fde76-fc22-484f-c7a7-69db03c91d24"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 30s 38ms/step - loss: 0.8894 - accuracy: 0.8584\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8893529176712036, 0.8583999872207642]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}